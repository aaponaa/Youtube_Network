{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Witch video \n",
    "VIDEO_ID = 'znxAgjeAgeQ'\n",
    "\n",
    "# Witch depth \n",
    "DEPTH = 3\n",
    "\n",
    "# YouTube Api Key \n",
    "API_KEY = \"AIzaSyAmMVcVEaofaqekOsgFa_ihAFEpdxFrv-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "import networkx as nx\n",
    "import time\n",
    "\n",
    "\n",
    "def get_video_recommendations(video_id, depth=2, G=None, parent=None):\n",
    "    \"\"\"\n",
    "    Retrieves YouTube video recommendations in cascade for a given video.\n",
    "\n",
    "    Arguments:\n",
    "    video_id: The YouTube video ID from which to retrieve recommendations.\n",
    "    depth: The depth of the cascade analysis of recommendations.\n",
    "    G: A networkx Graph object to store the relationships between videos. If none is provided, a new one will be created.\n",
    "    parent: The ID of the parent video. Used to connect videos in the graph.\n",
    "\n",
    "    Returns:\n",
    "    A networkx Graph object containing the relationships between videos.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a Service object to launch the Chrome browser\n",
    "    service = Service('chromedriver.exe')\n",
    "    service.start()\n",
    "\n",
    "    # If no graph is provided, create a new one\n",
    "    if G is None:\n",
    "        G = nx.Graph()\n",
    "\n",
    "    # Add the parent video to the graph, if it exists\n",
    "    if parent is not None:\n",
    "        if not G.has_node(parent):\n",
    "            G.add_node(parent)\n",
    "        G.add_edge(parent, video_id)\n",
    "    else:\n",
    "        G.add_node(video_id)\n",
    "\n",
    "    # Create a WebDriver object to control the Chrome browser in background\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('headless')\n",
    "    options.add_argument('disable-gpu')\n",
    "    driver = webdriver.Remote(service.service_url, options=options)\n",
    "    driver.get(f'https://www.youtube.com/watch?v={video_id}')\n",
    "\n",
    "    # Wait for the page to load\n",
    "    time.sleep(4)\n",
    "\n",
    "    # Extract the HTML code from the loaded page\n",
    "    html = driver.page_source\n",
    "\n",
    "    # If the depth is zero, stop the search\n",
    "    if depth == 0:\n",
    "        return G\n",
    "\n",
    "    # Create a BeautifulSoup object to extract the links from the page\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # Retrieve the first 10 recommended videos\n",
    "    recommendations = soup.find_all('a', {'class': 'yt-simple-endpoint style-scope ytd-compact-video-renderer'})\n",
    "    recommendations = [r['href'][9:] for r in recommendations if r['href'].startswith('/watch?v=')][:10]\n",
    "\n",
    "    # Add the recommended videos to the graph and continue the cascade search\n",
    "    for r in recommendations:\n",
    "        G.add_node(r)\n",
    "        G = get_video_recommendations(r, depth-1, G, video_id)\n",
    "\n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the vidéo recommendations\n",
    "G = get_video_recommendations(VIDEO_ID,3)\n",
    "\n",
    "# Show node count (videos) and link count (recommendations)\n",
    "print(f'Nombre de Nodes : {G.number_of_nodes()}')\n",
    "print(f'Nombre de Edges : {G.number_of_edges()}')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "nx.draw(G, with_labels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Id                                              title  \\\n",
      "0    8rvb8LpLTaA  Pertes de pouvoir et comment le reprendre - Je...   \n",
      "1    IOfQKUuvC-s       Vaccins Pfizer, le scandale des SMS continue   \n",
      "2    UGbMoIILPh8  Mieux gérer sa relation amoureuse et son parte...   \n",
      "3    Fjb72jZ3SpA  «La décroissance, on ne va pas y couper», selo...   \n",
      "4    O3vLIxeNNCY                      Chapter 14.3 - Faux-Semblants   \n",
      "..           ...                                                ...   \n",
      "488  OK8Bnfp48EI                PODCAST | Les messages de nos pieds   \n",
      "489  q_axRioN2Rw                              Thyroïde et digestion   \n",
      "490  5hmnTS_-l2U  Tout savoir sur le gluten & les intolérances a...   \n",
      "491  l8dW5TQxKk0  Comment diagnostiquer et lutter contre la care...   \n",
      "492  M4pSHsTh4m0      ASTUCE | La cuisson des viandes au Vitaliseur   \n",
      "\n",
      "                                           description  \\\n",
      "0    2ème partie http://youtu.be/UGbMoIILPh8\\n\\nChe...   \n",
      "1    Le quotidien américain New York Times vient d'...   \n",
      "2    LA TÉLÉ DE LILOU ©2013\\nWebTV http://www.latel...   \n",
      "3    Jean-Marc Jancovici, ingénieur polytechnicien ...   \n",
      "4    Provided to YouTube by Bookwire\\n\\nChapter 14....   \n",
      "..                                                 ...   \n",
      "488  Et si nous nous penchions sur nos pieds pour s...   \n",
      "489  Dr Stéphane Résimont - Médecin spécialisé en O...   \n",
      "490  Denis Riché fait une analyse claire et concise...   \n",
      "491  Interview de David Rey par Marion Kaplan. \\nPa...   \n",
      "492  Les conseils du Chef Stéphane Gabrielly accomp...   \n",
      "\n",
      "                                  channel  duration   views  \n",
      "0                   La Télé de Lilou Macé  PT39M55S  185837  \n",
      "1                      Journal l'Humanité  PT23M37S  472555  \n",
      "2                   La Télé de Lilou Macé     PT14M   93211  \n",
      "3                               Le Figaro  PT22M22S  282673  \n",
      "4                 Various Artists - Topic   PT4M17S       0  \n",
      "..                                    ...       ...     ...  \n",
      "488  Marion Kaplan & Vitaliseur de Marion  PT36M38S   59248  \n",
      "489  Marion Kaplan & Vitaliseur de Marion  PT30M20S   32830  \n",
      "490  Marion Kaplan & Vitaliseur de Marion   PT43M3S   15399  \n",
      "491  Marion Kaplan & Vitaliseur de Marion  PT22M50S   23280  \n",
      "492  Marion Kaplan & Vitaliseur de Marion  PT21M27S   17733  \n",
      "\n",
      "[493 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# Retrieve a list of each node in the graph\n",
    "nodes_list = list(G.nodes())\n",
    "\n",
    "# Create an empty database with columns for the information you want to retrieve\n",
    "df = pd.DataFrame(columns=[\"Id\", \"title\", \"description\", \"channel\", \"duration\", \"views\"])\n",
    "\n",
    "# Loop over each node and retrieve information from the YouTube API\n",
    "for video_id in nodes_list:\n",
    "        \n",
    "    # Send a request to the YouTube API to retrieve video information\n",
    "    url = f\"https://www.googleapis.com/youtube/v3/videos?id={video_id}&key={API_KEY}&part=snippet,contentDetails,statistics\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # If the query is successful and video information is returned, add information to the database\n",
    "    if response.status_code == 200:\n",
    "        video_info = response.json().get(\"items\", [])\n",
    "        if len(video_info) > 0:\n",
    "            video_info = video_info[0]\n",
    "            title = video_info[\"snippet\"][\"title\"]\n",
    "            description = video_info[\"snippet\"][\"description\"]\n",
    "            channel = video_info[\"snippet\"][\"channelTitle\"]\n",
    "            duration = video_info[\"contentDetails\"][\"duration\"]\n",
    "            views = video_info[\"statistics\"][\"viewCount\"]\n",
    "            new_row = pd.DataFrame({\"Id\": video_id, \"title\": title, \"description\": description, \"channel\": channel, \"duration\": duration, \"views\": views}, index=[0])\n",
    "            df = pd.concat([df, new_row], ignore_index=True)\n",
    "    \n",
    "# Show database\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "# Create the VIDEO_ID directory if it doesn't exist\n",
    "if not os.path.exists(f'data/{VIDEO_ID}'):\n",
    "    os.makedirs(f'data/{VIDEO_ID}')\n",
    "\n",
    "# save the graph in CSV format as Edges list\n",
    "nx.write_edgelist(G, f'data/{VIDEO_ID}/edges.csv', delimiter=',',data=False)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(f'data/{VIDEO_ID}/nodes.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81bd72421fd5d63e4ee9fa784821c92c07d954c88ac6df7776d2c7cf9a96f666"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
